{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MoBioFP - Model Training For Fingertip Semantic Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import imutils\n",
    "import platform\n",
    "import albumentations as A\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.optimizers.legacy import Adam as AdamLegacy\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from mobiofp.segmentation import Segment, DataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_DIR_PATH = \"UNET_DATASET_IMAGE_DIR_PATH\"\n",
    "LABELS_DIR_PATH = \"UNET_DATASET_MASK_DIR_PATH\"\n",
    "MODEL_CHECKPOINT_PATH = \"UNET_MODEL_CHECKPOINT_PATH\"\n",
    "EPOCHS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define data augmentation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_clip_0_1(x, **kwargs):\n",
    "    \"\"\"\n",
    "    Rounds the input to the nearest integer and clips it to the range [0, 1].\n",
    "\n",
    "    Parameters:\n",
    "        x (np.array): The input array to round and clip.\n",
    "        **kwargs: Arbitrary keyword arguments. This is included to maintain compatibility with the albumentations library, which may pass additional arguments.\n",
    "\n",
    "    Returns:\n",
    "        np.array: The rounded and clipped input array.\n",
    "    \"\"\"\n",
    "    return x.round().clip(0, 1)\n",
    "\n",
    "\n",
    "def training_augmentation():\n",
    "    \"\"\"\n",
    "    Defines the augmentation pipeline for training data.\n",
    "\n",
    "    Returns:\n",
    "        albumentations.Compose: The augmentation pipeline.\n",
    "    \"\"\"\n",
    "    train_transform = [\n",
    "        A.PadIfNeeded(min_height=256, min_width=256, always_apply=True, border_mode=0),\n",
    "        # Flip augmentations\n",
    "        A.OneOf(\n",
    "            [A.HorizontalFlip(p=1), A.VerticalFlip(p=1), A.Transpose(p=1)],\n",
    "            p=0.9,\n",
    "        ),\n",
    "        # Geometric augmentations\n",
    "        A.OneOf(\n",
    "            [\n",
    "                A.ShiftScaleRotate(\n",
    "                    scale_limit=0.3,\n",
    "                    rotate_limit=45,\n",
    "                    shift_limit=0.2,\n",
    "                    border_mode=0,\n",
    "                    p=1,\n",
    "                ),\n",
    "                A.Perspective(p=1),\n",
    "            ],\n",
    "            p=0.9,\n",
    "        ),\n",
    "        # Resolution augmentation\n",
    "        A.OneOf(\n",
    "            [\n",
    "                A.Sharpen(p=1),\n",
    "                A.Blur(blur_limit=3, p=1),\n",
    "                A.MotionBlur(blur_limit=3, p=1),\n",
    "            ],\n",
    "            p=0.9,\n",
    "        ),\n",
    "        # Visual alterations\n",
    "        A.OneOf(\n",
    "            [\n",
    "                A.HueSaturationValue(\n",
    "                    hue_shift_limit=1, sat_shift_limit=0.2, val_shift_limit=0.5, p=1\n",
    "                ),\n",
    "                A.RandomBrightnessContrast(p=1),\n",
    "            ],\n",
    "            p=0.5,\n",
    "        ),\n",
    "        A.Lambda(mask=round_clip_0_1),\n",
    "    ]\n",
    "\n",
    "    return A.Compose(train_transform)\n",
    "\n",
    "\n",
    "def validation_augmentation():\n",
    "    \"\"\"\n",
    "    Defines the augmentation pipeline for validation data.\n",
    "\n",
    "    Returns:\n",
    "        albumentations.Compose: The augmentation pipeline.\n",
    "    \"\"\"\n",
    "    test_transform = [A.PadIfNeeded(256, 256)]\n",
    "\n",
    "    return A.Compose(test_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataset\n",
    "\n",
    "Load images and semantic segmentation labels, dividing the dataset into a training subset (85%) and a validation subset (15%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_dir = sorted(os.listdir(IMAGE_DIR_PATH))\n",
    "labels_dir = sorted(os.listdir(LABELS_DIR_PATH))\n",
    "training_images, validation_images, training_labels, validation_labels = train_test_split(\n",
    "    images_dir, labels_dir, test_size=0.15, random_state=42\n",
    ")\n",
    "\n",
    "# Check if the dataset is loaded correctly\n",
    "assert len(training_images) == len(training_labels) and len(validation_images) == len(\n",
    "    validation_labels\n",
    "), \"Dataset not loaded correctly\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training and validation parameters\n",
    "training_params = {\n",
    "    \"augmentation\": training_augmentation(),\n",
    "    \"preprocessing\": None,\n",
    "    \"batch_size\": 8,\n",
    "    \"dim\": (256, 256, 3),\n",
    "    \"shuffle\": True,\n",
    "}\n",
    "validation_params = {\n",
    "    \"augmentation\": validation_augmentation(),\n",
    "    \"preprocessing\": None,\n",
    "    \"batch_size\": 8,\n",
    "    \"dim\": (256, 256, 3),\n",
    "    \"shuffle\": True,\n",
    "}\n",
    "\n",
    "# Generate training and validation datasets using the DataGenerator class\n",
    "training_dataset = DataGenerator(\n",
    "    training_images, IMAGE_DIR_PATH, training_labels, LABELS_DIR_PATH, **training_params\n",
    ")\n",
    "validation_dataset = DataGenerator(\n",
    "    validation_images, IMAGE_DIR_PATH, validation_labels, LABELS_DIR_PATH, **validation_params\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model metrics functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_distance_loss(y_true, y_pred, smooth=100):\n",
    "    \"\"\"\n",
    "    Calculates the Jaccard distance loss between the true and predicted labels.\n",
    "\n",
    "    Parameters:\n",
    "    y_true (tf.Tensor): The true labels.\n",
    "    y_pred (tf.Tensor): The predicted labels.\n",
    "    smooth (int, optional): A smoothing factor to prevent division by zero. Defaults to 100.\n",
    "\n",
    "    Returns:\n",
    "        tf.Tensor: The Jaccard distance loss.\n",
    "    \"\"\"\n",
    "    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n",
    "    sum_ = K.sum(K.abs(y_true) + K.abs(y_pred), axis=-1)\n",
    "    jac = (intersection + smooth) / (sum_ - intersection + smooth)\n",
    "\n",
    "    return (1 - jac) * smooth\n",
    "\n",
    "\n",
    "def dice_coef(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculates the Dice coefficient between the true and predicted labels.\n",
    "\n",
    "    Parameters:\n",
    "        y_true (tf.Tensor): The true labels.\n",
    "        y_pred (tf.Tensor): The predicted labels.\n",
    "\n",
    "    Returns:\n",
    "        tf.Tensor: The Dice coefficient.\n",
    "    \"\"\"\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "\n",
    "    return (2.0 * intersection + K.epsilon()) / (K.sum(y_true_f) + K.sum(y_pred_f) + K.epsilon())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Segment()\n",
    "model.info()\n",
    "\n",
    "if platform.system() == \"Darwin\":\n",
    "    # Use the legacy Adam optimizer on M1/M2 Macs\n",
    "    optim = AdamLegacy(learning_rate=0.0001)\n",
    "else:\n",
    "    # Use the new Adam optimizer on other platforms\n",
    "    optim = Adam(learning_rate=0.0001)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optim,\n",
    "    loss=jaccard_distance_loss,\n",
    "    metrics=[\n",
    "        dice_coef,\n",
    "        \"accuracy\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss0, dice_coef0, accuracy0 = model.evaluate(validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"initial loss: {loss0:.2f}\")\n",
    "print(f\"initial dice coefficient: {dice_coef0:.2f}\")\n",
    "print(f\"initial accuracy: {accuracy0:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    ModelCheckpoint(\n",
    "        MODEL_CHECKPOINT_PATH,\n",
    "        save_weights_only=True,\n",
    "        save_best_only=True,\n",
    "        mode=\"min\",\n",
    "    ),\n",
    "    ReduceLROnPlateau(),\n",
    "    EarlyStopping(mode=\"max\", monitor=\"val_dice_coef\", patience=3, verbose=1),\n",
    "]\n",
    "history = model.train(training_dataset, validation_dataset, epochs=EPOCHS, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history[\"accuracy\"]\n",
    "val_acc = history.history[\"val_accuracy\"]\n",
    "\n",
    "loss = history.history[\"loss\"]\n",
    "val_loss = history.history[\"val_loss\"]\n",
    "\n",
    "dice_coef = history.history[\"dice_coef\"]\n",
    "val_dice_coef = history.history[\"val_dice_coef\"]\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.plot(acc, label=\"Training Accuracy\")\n",
    "plt.plot(val_acc, label=\"Validation Accuracy\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.ylim([min(plt.ylim()), 1])\n",
    "plt.title(\"Training and Validation Accuracy\")\n",
    "\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.plot(loss, label=\"Training Loss\")\n",
    "plt.plot(val_loss, label=\"Validation Loss\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.ylim([0, 1.0])\n",
    "plt.title(\"Training and Validation Loss\")\n",
    "\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.plot(dice_coef, label=\"Training Dice Coefficient\")\n",
    "plt.plot(val_dice_coef, label=\"Validation Dice Coefficient\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.ylim([0, 1.0])\n",
    "plt.title(\"Training and Validation Dice Coefficient\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"../data/raw/samples/1_i_1_w_1.jpg\")\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "image = imutils.rotate_bound(image, 90)\n",
    "result = model.predict(image)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(image)\n",
    "plt.title(\"Original Image\")\n",
    "plt.axis(\"off\")\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(result, cmap=\"gray\")\n",
    "plt.title(\"Segmented Image\")\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jolene3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
