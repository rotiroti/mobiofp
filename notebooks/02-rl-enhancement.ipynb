{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MoBioFP - Fingertip Enhancement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env SM_FRAMEWORK=tf.keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "from tensorflow.keras.layers import (\n",
    "    Input,\n",
    "    Conv2D,\n",
    "    MaxPooling2D,\n",
    "    concatenate,\n",
    "    Conv2DTranspose,\n",
    "    BatchNormalization,\n",
    "    Activation,\n",
    "    Dropout,\n",
    ")\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_CHECKPOINT_PATH = \"../models/best-iiitd-unet-arm64.h5\"\n",
    "PREDICTED_MASK_DIR_PATH = \"../data/raw/iiitd-sample/1_i_1_n_1.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create convolutional block\n",
    "def conv_block(tensor, nfilters, size=3, padding=\"same\", initializer=\"he_normal\"):\n",
    "    x = Conv2D(\n",
    "        filters=nfilters,\n",
    "        kernel_size=(size, size),\n",
    "        padding=padding,\n",
    "        kernel_initializer=initializer,\n",
    "    )(tensor)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = Conv2D(\n",
    "        filters=nfilters,\n",
    "        kernel_size=(size, size),\n",
    "        padding=padding,\n",
    "        kernel_initializer=initializer,\n",
    "    )(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "# Function to create encoder block\n",
    "def encoder_block(inputs, n_filters):\n",
    "    conv = conv_block(inputs, n_filters)\n",
    "    pool = MaxPooling2D(pool_size=(2, 2))(conv)\n",
    "\n",
    "    return pool, conv\n",
    "\n",
    "\n",
    "# Function to create decoder block\n",
    "def decoder_block(inputs, conv_output, n_filters):\n",
    "    deconv = Conv2DTranspose(\n",
    "        n_filters, kernel_size=(3, 3), strides=(2, 2), padding=\"same\"\n",
    "    )(inputs)\n",
    "    concat = concatenate([deconv, conv_output], axis=3)\n",
    "    conv = conv_block(concat, n_filters)\n",
    "\n",
    "    return conv\n",
    "\n",
    "\n",
    "# Function to create U-Net model\n",
    "def create_unet(input_shape, n_filters=64):\n",
    "    inputs = Input(shape=input_shape, name=\"image_input\")\n",
    "    p1, c1 = encoder_block(inputs, n_filters)\n",
    "    p2, c2 = encoder_block(p1, n_filters * 2)\n",
    "    p3, c3 = encoder_block(p2, n_filters * 4)\n",
    "    p4, c4 = encoder_block(p3, n_filters * 8)\n",
    "    p4 = Dropout(0.5)(p4)\n",
    "    c5 = conv_block(p4, n_filters * 16)\n",
    "    c5 = Dropout(0.5)(c5)\n",
    "    d6 = decoder_block(c5, c4, n_filters * 8)\n",
    "    d6 = Dropout(0.5)(d6)\n",
    "    d7 = decoder_block(d6, c3, n_filters * 4)\n",
    "    d7 = Dropout(0.5)(d7)\n",
    "    d8 = decoder_block(d7, c2, n_filters * 2)\n",
    "    d9 = decoder_block(d8, c1, n_filters)\n",
    "    outputs = Conv2D(filters=1, kernel_size=(1, 1), activation=\"sigmoid\")(d9)\n",
    "    model = Model(inputs=inputs, outputs=outputs, name=\"Unet\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the model\n",
    "model = create_unet(input_shape=(256, 256, 3), n_filters=64)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_largest_connected_component(mask: np.ndarray) -> np.array:\n",
    "    \"\"\"\n",
    "    Finds the largest connected component in a binary mask.\n",
    "    Args:\n",
    "        mask: Binary mask containing connected components.\n",
    "    Returns:\n",
    "        Binary mask with only the largest connected component.\n",
    "    \"\"\"\n",
    "\n",
    "    # Use OpenCV's connectedComponentsWithStats to find connected components\n",
    "    _, labels, stats, _ = cv2.connectedComponentsWithStats(mask, connectivity=8)\n",
    "\n",
    "    # Find the index of the largest connected component (excluding background)\n",
    "    largest_component_index = np.argmax(stats[1:, cv2.CC_STAT_AREA]) + 1\n",
    "\n",
    "    # Create a mask with only the largest connected component\n",
    "    largest_component_mask = np.uint8(labels == largest_component_index)\n",
    "\n",
    "    return largest_component_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load image\n",
    "image = cv2.imread(PREDICTED_MASK_DIR_PATH)\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(image)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess image\n",
    "image_resized = cv2.resize(image, (256, 256)) / 255.0\n",
    "image_input = np.expand_dims(image_resized, axis=0)\n",
    "\n",
    "# Load model weights\n",
    "model.load_weights(MODEL_CHECKPOINT_PATH)\n",
    "\n",
    "# Predict the mask\n",
    "pred_mask = (model.predict(image_input) > 0.5).astype(np.uint8).reshape(256, 256)\n",
    "\n",
    "# Resize the mask to the original image size\n",
    "fingertip_mask = cv2.resize(pred_mask, (image.shape[1], image.shape[0]))\n",
    "\n",
    "# Apply morphological operations (closing) to remove small holes in the mask\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (11, 11))\n",
    "closing_mask = cv2.morphologyEx(fingertip_mask, cv2.MORPH_CLOSE, kernel, iterations=2)\n",
    "\n",
    "# Apply bilateral filter\n",
    "d = 15  # Diameter of pixel neighborhood for filtering\n",
    "sigma_color = 75  # Filter sigma in the color space\n",
    "sigma_space = 75  # Filter sigma in the coordinate space\n",
    "bilateral_mask = cv2.bilateralFilter(closing_mask, d, sigma_color, sigma_space)\n",
    "\n",
    "# Find the largest connected component\n",
    "lcc_mask = find_largest_connected_component(bilateral_mask)\n",
    "\n",
    "# Apply dilation\n",
    "mask = cv2.dilate(lcc_mask, kernel, iterations=2)\n",
    "\n",
    "plt.figure(figsize=(20, 15))\n",
    "plt.subplot(3, 3, 1)\n",
    "plt.imshow(image)\n",
    "plt.title(\"Original Image\")\n",
    "plt.axis(\"off\")\n",
    "plt.subplot(3, 3, 2)\n",
    "plt.imshow(fingertip_mask, cmap=\"gray\")\n",
    "plt.title(\"Predicted Fingertip Mask\")\n",
    "plt.axis(\"off\")\n",
    "plt.subplot(3, 3, 3)\n",
    "plt.imshow(closing_mask, cmap=\"gray\")\n",
    "plt.title(\"Morhological Closing\")\n",
    "plt.axis(\"off\")\n",
    "plt.subplot(3, 3, 4)\n",
    "plt.imshow(bilateral_mask, cmap=\"gray\")\n",
    "plt.title(\"Bi-Lateral Filter\")\n",
    "plt.axis(\"off\")\n",
    "plt.subplot(3, 3, 5)\n",
    "plt.imshow(lcc_mask, cmap=\"gray\")\n",
    "plt.title(\"Largest Connected Component\")\n",
    "plt.axis(\"off\")\n",
    "plt.subplot(3, 3, 6)\n",
    "plt.imshow(mask, cmap=\"gray\")\n",
    "plt.title(\"Morhological Dilation\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_roi(mask: np.ndarray) -> tuple[int, int, int, int]:\n",
    "    \"\"\"\n",
    "    Extract ROI from a binary mask\n",
    "    Args:\n",
    "        mask: Binary mask.\n",
    "    Returns:\n",
    "        Tuple with four coordinates representing the bounding box rectangle.\n",
    "    \"\"\"\n",
    "    cnts, _ = cv2.findContours(\n",
    "        mask.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE\n",
    "    )\n",
    "    cnt = max(cnts, key=cv2.contourArea)\n",
    "    x, y, w, h = cv2.boundingRect(cnt)\n",
    "\n",
    "    return (x, y, w, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract ROI (finger)\n",
    "(x, y, w, h) = extract_roi(mask)\n",
    "\n",
    "# Create a rectangle patch for the ROI\n",
    "roi_rect = patches.Rectangle((x, y), w, h, linewidth=1, edgecolor=\"r\", facecolor=\"none\")\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 7))\n",
    "axes[0].imshow(image)\n",
    "axes[0].add_patch(roi_rect)\n",
    "axes[0].set_title(\"Original Image: Fingertip ROI\")\n",
    "\n",
    "# Crop the ROI from the original image\n",
    "roi = image[y : y + h, x : x + w]\n",
    "roi_mask = mask[y : y + h, x : x + w]\n",
    "\n",
    "axes[1].imshow(roi)\n",
    "axes[1].set_title(\"Segmented Fingertip\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fingertip - Gamma Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import img_as_float\n",
    "from skimage import exposure\n",
    "\n",
    "\n",
    "def plot_img_and_hist(image, axes, bins=256):\n",
    "    \"\"\"Plot an image along with its histogram and cumulative histogram.\"\"\"\n",
    "    image = img_as_float(image)\n",
    "    ax_img, ax_hist = axes\n",
    "    ax_cdf = ax_hist.twinx()\n",
    "\n",
    "    # Display image\n",
    "    ax_img.imshow(image, cmap=plt.cm.gray)\n",
    "    ax_img.set_axis_off()\n",
    "\n",
    "    # Display histogram\n",
    "    ax_hist.hist(image.ravel(), bins=bins, histtype=\"step\", color=\"black\")\n",
    "    ax_hist.ticklabel_format(axis=\"y\", style=\"scientific\", scilimits=(0, 0))\n",
    "    ax_hist.set_xlabel(\"Pixel intensity\")\n",
    "    ax_hist.set_xlim(0, 1)\n",
    "    ax_hist.set_yticks([])\n",
    "\n",
    "    # Display cumulative distribution\n",
    "    img_cdf, bins = exposure.cumulative_distribution(image, bins)\n",
    "    ax_cdf.plot(bins, img_cdf, \"r\")\n",
    "    ax_cdf.set_yticks([])\n",
    "\n",
    "    return ax_img, ax_hist, ax_cdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fingertip Enhancement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to grayscale\n",
    "fingertip_gray = cv2.cvtColor(roi, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "# Gamma\n",
    "gamma_corrected = exposure.adjust_gamma(fingertip_gray, 2)\n",
    "\n",
    "# Logarithmic\n",
    "logarithmic_corrected = exposure.adjust_log(fingertip_gray, 1)\n",
    "\n",
    "# Display results\n",
    "fig = plt.figure(figsize=(15, 7))\n",
    "axes = np.zeros((2, 3), dtype=object)\n",
    "axes[0, 0] = plt.subplot(2, 3, 1)\n",
    "axes[0, 1] = plt.subplot(2, 3, 2, sharex=axes[0, 0], sharey=axes[0, 0])\n",
    "axes[0, 2] = plt.subplot(2, 3, 3, sharex=axes[0, 0], sharey=axes[0, 0])\n",
    "axes[1, 0] = plt.subplot(2, 3, 4)\n",
    "axes[1, 1] = plt.subplot(2, 3, 5)\n",
    "axes[1, 2] = plt.subplot(2, 3, 6)\n",
    "\n",
    "ax_img, ax_hist, ax_cdf = plot_img_and_hist(fingertip_gray, axes[:, 0])\n",
    "ax_img.set_title(\"Grayscale Fingertip\")\n",
    "\n",
    "y_min, y_max = ax_hist.get_ylim()\n",
    "ax_hist.set_ylabel(\"Number of pixels\")\n",
    "ax_hist.set_yticks(np.linspace(0, y_max, 5))\n",
    "\n",
    "ax_img, ax_hist, ax_cdf = plot_img_and_hist(gamma_corrected, axes[:, 1])\n",
    "ax_img.set_title(\"Gamma correction\")\n",
    "\n",
    "ax_img, ax_hist, ax_cdf = plot_img_and_hist(logarithmic_corrected, axes[:, 2])\n",
    "ax_img.set_title(\"Logarithmic correction\")\n",
    "\n",
    "ax_cdf.set_ylabel(\"Fraction of total intensity\")\n",
    "ax_cdf.set_yticks(np.linspace(0, 1, 5))\n",
    "\n",
    "# prevent overlap of y-axis labels\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fingertip - Enhancement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Remove speckle noise by applying a median blur\n",
    "median = cv2.medianBlur(logarithmic_corrected, 5)\n",
    "\n",
    "# 2. Apply adaptive histogram equalization (CLAHE) to mitigate the effect of illumination variations\n",
    "equalized = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8)).apply(median)\n",
    "\n",
    "# 3. Sharpen the image by substracting the Gaussian blurred image (sigma=2) from the previous image\n",
    "gaussian = cv2.GaussianBlur(equalized, (7, 7), 2)\n",
    "sharpened = cv2.addWeighted(equalized, 1.5, gaussian, -0.5, 0)\n",
    "\n",
    "enhancements = [\n",
    "    logarithmic_corrected,\n",
    "    median,\n",
    "    equalized,\n",
    "    gaussian,\n",
    "    sharpened,\n",
    "    # non_local_means\n",
    "]\n",
    "enhancements_titles = [\n",
    "    \"Original Image\",\n",
    "    \"Median Blur (kernel=5x5)\",\n",
    "    \"Adaptive Histogram Equalization\",\n",
    "    \"Gaussian Blur (kernel=7x7, sigma=2)\",\n",
    "    \"Sharpened\",\n",
    "]\n",
    "\n",
    "plt.figure(figsize=(15, 20))\n",
    "\n",
    "for i, (enhancement, title) in enumerate(zip(enhancements, enhancements_titles)):\n",
    "    plt.subplot(5, 2, 2 * i + 1)\n",
    "    plt.imshow(enhancement, cmap=\"gray\")\n",
    "    plt.title(title)\n",
    "\n",
    "    plt.subplot(5, 2, 2 * i + 2)\n",
    "    hist = cv2.calcHist([enhancement], [0], None, [256], [0, 256])\n",
    "    hist /= hist.sum()\n",
    "    plt.plot(hist)\n",
    "    plt.xlim([0, 256])\n",
    "    plt.xlabel(\"Pixel Value\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
