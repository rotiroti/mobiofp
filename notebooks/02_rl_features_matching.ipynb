{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MoBioFP - Feature Extraction and Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define global constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processed Sample Directory (results of the pre-processing using figertip object detection)\n",
    "SAMPLE_DIR = \"../data/processed/samples/detection\"\n",
    "\n",
    "# # Processed Sample Directory (results of the pre-processing using figertip semantic segmentation)\n",
    "# SAMPLE_DIR = \"../data/processed/samples/segmentation\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(images, titles, cmap=\"gray\", show_axis=False, fig_size=10, sup_title=None, limit=8):\n",
    "    assert (titles is None) or (len(images) == len(titles))\n",
    "\n",
    "    # Limit the number of images and titles\n",
    "    images = images[:limit]\n",
    "    titles = titles[:limit] if titles else None\n",
    "\n",
    "    num_images = len(images)\n",
    "    num_cols = 4\n",
    "    num_rows = math.ceil(num_images / num_cols)\n",
    "\n",
    "    fig_height = fig_size * (num_rows / num_cols) * 1.5\n",
    "    _, axes = plt.subplots(\n",
    "        num_rows, num_cols, figsize=(fig_size, fig_height), constrained_layout=True\n",
    "    )\n",
    "    axes = axes.ravel()\n",
    "\n",
    "    if sup_title:\n",
    "        plt.suptitle(sup_title, fontsize=24)\n",
    "\n",
    "    for idx, (image, title) in enumerate(zip(images, titles)):\n",
    "        axes[idx].imshow(image, cmap=cmap)\n",
    "        axes[idx].set_title(title, fontsize=12)\n",
    "        axes[idx].axis(\"on\" if show_axis else \"off\")\n",
    "\n",
    "    # Hide the remaining subplots\n",
    "    for idx in range(num_images, num_cols * num_rows):\n",
    "        axes[idx].axis(\"off\")\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "def split_probe_gallery(images, images_titles):\n",
    "    NUM_TEMPLATES = 4  # Number of templates for each subject\n",
    "    subjects = {}\n",
    "\n",
    "    for title in images_titles:\n",
    "        subject_id, _, _, _ = title.split(\"_\")\n",
    "\n",
    "        if subject_id in subjects:\n",
    "            subjects[subject_id] += 1\n",
    "        else:\n",
    "            subjects[subject_id] = 1\n",
    "\n",
    "    for subject_id in list(subjects.keys()):\n",
    "        # Remove the subject if it does not have the required number of templates\n",
    "        if subjects[subject_id] != NUM_TEMPLATES:\n",
    "            del subjects[subject_id]\n",
    "\n",
    "    probe = []\n",
    "    gallery = []\n",
    "\n",
    "    # 2. Split the images into probe and gallery by using the filtered subjects dictionary\n",
    "    for image, title in zip(images, images_titles):\n",
    "        subject_id, illumination, finger_id, background = title.split(\"_\")\n",
    "\n",
    "        if subject_id in subjects:\n",
    "            if illumination == \"o\" and background == \"n\":\n",
    "                probe.append((image, title))\n",
    "            elif illumination == \"i\" and background == \"w\":\n",
    "                gallery.append((image, title))\n",
    "            else:\n",
    "                print(f\"Skipping template: {title}\")\n",
    "\n",
    "    assert len(probe) == len(gallery)\n",
    "\n",
    "    # 3. Sort the probe and gallery images based on the subject id\n",
    "    probe = sorted(probe, key=lambda x: x[1])\n",
    "    gallery = sorted(gallery, key=lambda x: x[1])\n",
    "\n",
    "    return probe, gallery\n",
    "\n",
    "\n",
    "def bf_matcher(img1, kp1, desc1, img2, kp2, desc2):\n",
    "    # Create a brute-force matcher object\n",
    "    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "\n",
    "    # Perform the matching between the two descriptor sets\n",
    "    matches = bf.match(desc1, desc2)\n",
    "\n",
    "    # Sort the matches based on distance\n",
    "    matches = sorted(matches, key=lambda x: x.distance)\n",
    "\n",
    "    # Draw the matches\n",
    "    matches_img = cv2.drawMatches(img1, kp1, img2, kp2, matches, None)\n",
    "\n",
    "    # Compute median distance\n",
    "    distance = np.median([m.distance for m in matches])\n",
    "\n",
    "    return distance, matches_img\n",
    "\n",
    "\n",
    "def flann_matcher(img1, kp1, desc1, img2, kp2, desc2):\n",
    "    FLANN_INDEX_LSH = 6\n",
    "    index_params = dict(algorithm=FLANN_INDEX_LSH, table_number=6, key_size=12, multi_probe_level=1)\n",
    "    search_params = dict(checks=50)\n",
    "\n",
    "    # Create a FLANN matcher object\n",
    "    flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "    matches = flann.knnMatch(desc1, desc2, k=2)\n",
    "\n",
    "    # Apply ratio test\n",
    "    good_matches = []\n",
    "    for match in matches:\n",
    "        if len(match) >= 2:\n",
    "            m, n = match\n",
    "            if m.distance < 0.75 * n.distance:\n",
    "                good_matches.append(m)\n",
    "\n",
    "    # Draw the good matches\n",
    "    matches_img = cv2.drawMatches(img1, kp1, img2, kp2, good_matches, None)\n",
    "\n",
    "    # Compute median distance\n",
    "    if good_matches:\n",
    "        distance = np.median([m.distance for m in good_matches])\n",
    "        # Check if distance is nan or inf, if so, set it to a large number\n",
    "        if np.isnan(distance) or np.isinf(distance):\n",
    "            distance = float(\"inf\")\n",
    "    else:\n",
    "        distance = float(\"inf\")\n",
    "\n",
    "    return distance, matches_img\n",
    "\n",
    "\n",
    "def distance_matrix(\n",
    "    probe_images,\n",
    "    probe_titles,\n",
    "    probe_orb_keypoints,\n",
    "    probe_orb_descriptors,\n",
    "    gallery_images,\n",
    "    gallery_titles,\n",
    "    gallery_orb_keypoints,\n",
    "    gallery_orb_descriptors,\n",
    "    matcher=flann_matcher,\n",
    "    matched_img=False,\n",
    "):\n",
    "    distances = {p: [] for p in probe_titles}\n",
    "\n",
    "    for p_im, p_title, p_kp, p_desc in zip(\n",
    "        probe_images, probe_titles, probe_orb_keypoints, probe_orb_descriptors\n",
    "    ):\n",
    "        for g_im, g_title, g_kp, g_desc in zip(\n",
    "            gallery_images, gallery_titles, gallery_orb_keypoints, gallery_orb_descriptors\n",
    "        ):\n",
    "            if not check(p_title, g_title):\n",
    "                continue\n",
    "\n",
    "            values = {}\n",
    "            values[g_title] = {}\n",
    "            distance, matches_img = matcher(p_im, p_kp, p_desc, g_im, g_kp, g_desc)\n",
    "            if np.isnan(distance) or np.isinf(distance):\n",
    "                distance = -1\n",
    "\n",
    "            values[g_title][\"distance\"] = distance\n",
    "\n",
    "            if matched_img:\n",
    "                values[g_title][\"matches_img\"] = matches_img\n",
    "            distances[p_title].append(values)\n",
    "\n",
    "    return distances\n",
    "\n",
    "\n",
    "def check(probe_title, gallery_title):\n",
    "    _, probe_illumination, probe_finger, probe_background = probe_title.split(\"_\")\n",
    "    _, gallery_illumination, gallery_finger, gallery_background = gallery_title.split(\"_\")\n",
    "\n",
    "    return (\n",
    "        probe_illumination == \"o\"\n",
    "        and gallery_illumination == \"i\"\n",
    "        and probe_background == \"n\"\n",
    "        and gallery_background == \"w\"\n",
    "        and probe_finger == gallery_finger\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Fingerprint Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_paths = list(Path(SAMPLE_DIR).rglob(\"*.png\"))\n",
    "images = []\n",
    "images_titles = []\n",
    "\n",
    "for p in images_paths:\n",
    "    img = cv2.imread(str(p), cv2.IMREAD_GRAYSCALE)\n",
    "    images.append(img)\n",
    "    images_titles.append(p.stem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Fingerprint into Probe (NO) and Gallery (WI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probe, gallery = split_probe_gallery(images, images_titles)\n",
    "probe_images, probe_titles = zip(*probe)\n",
    "gallery_images, gallery_titles = zip(*gallery)\n",
    "\n",
    "print(f\"Probe (NO) # templates (1 subject, 2 templates): {len(probe)}\")\n",
    "print(f\"Gallery (WI) # subjects (1 subject, 2 templates): {len(gallery)}\")\n",
    "\n",
    "# Uncomment these lines to apply Zhang-Suen thinning algorithm to the images\n",
    "# probe_images = [cv2.ximgproc.thinning(img) for img in probe_images]\n",
    "# gallery_images = [cv2.ximgproc.thinning(img) for img in gallery_images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images(probe_images, probe_titles, fig_size=8, sup_title=\"Probe (NO) Fingerprint Images\")\n",
    "show_images(gallery_images, gallery_titles, fig_size=8, sup_title=\"Gallery (WI) Fingerprint Images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. ORB (Oriented FAST and Rotated BRIEF)\n",
    "\n",
    "REF: https://docs.opencv.org/4.x/dc/dc3/tutorial_py_matcher.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the ORB detector\n",
    "orb = cv2.ORB_create()\n",
    "\n",
    "# Find the keypoints and descriptors for the probe and gallery images\n",
    "probe_orb_keypoints, probe_orb_descriptors = zip(\n",
    "    *[orb.detectAndCompute(image, None) for image in probe_images]\n",
    ")\n",
    "gallery_orb_keypoints, gallery_orb_descriptors = zip(\n",
    "    *[orb.detectAndCompute(image, None) for image in gallery_images]\n",
    ")\n",
    "\n",
    "# Show keypoints for each probe and images\n",
    "probe_orb_keypoints_images = [\n",
    "    imkpts(image, keypoints) for image, keypoints in zip(probe_images, probe_orb_keypoints)\n",
    "]\n",
    "gallery_orb_keypoints_images = [\n",
    "    imkpts(image, keypoints) for image, keypoints in zip(gallery_images, gallery_orb_keypoints)\n",
    "]\n",
    "\n",
    "show_images(\n",
    "    probe_orb_keypoints_images, probe_titles, fig_size=15, sup_title=\"Probe (NO) ORB Keypoints\"\n",
    ")\n",
    "show_images(\n",
    "    gallery_orb_keypoints_images,\n",
    "    gallery_titles,\n",
    "    fig_size=15,\n",
    "    sup_title=\"Gallery (WI) ORB Keypoints\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute Distance Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = distance_matrix(\n",
    "    probe_images,\n",
    "    probe_titles,\n",
    "    probe_orb_keypoints,\n",
    "    probe_orb_descriptors,\n",
    "    gallery_images,\n",
    "    gallery_titles,\n",
    "    gallery_orb_keypoints,\n",
    "    gallery_orb_descriptors,\n",
    "    matched_img=True,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jolene3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
