{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MoBioFP - Feature Matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Python Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define global constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_DIR = \"../data/processed/samples/detection\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def show_images(images, titles, cmap=\"gray\", show_axis=False, fig_size=10, sup_title=None):\n",
    "    assert((titles is None) or (len(images) == len(titles)))\n",
    "\n",
    "    num_images = len(images)\n",
    "    num_cols = 4\n",
    "    num_rows = math.ceil(num_images / num_cols)\n",
    "\n",
    "    fig_height = fig_size * (num_rows / num_cols) * 1.5\n",
    "    _, axes = plt.subplots(num_rows, num_cols, figsize=(fig_size, fig_height), constrained_layout=True)\n",
    "    axes = axes.ravel()\n",
    "\n",
    "    if sup_title:\n",
    "        plt.suptitle(sup_title, fontsize=24)\n",
    "\n",
    "    for idx, (image, title) in enumerate(zip(images, titles)):\n",
    "        axes[idx].imshow(image, cmap=cmap)\n",
    "        axes[idx].set_title(title, fontsize=12)\n",
    "        axes[idx].axis(\"on\" if show_axis else \"off\")\n",
    "    \n",
    "    # Hide the remaining subplots\n",
    "    for idx in range(num_images, num_cols * num_rows):\n",
    "        axes[idx].axis(\"off\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "def imkpts(image, keypoints):\n",
    "    result = cv2.drawKeypoints(image, keypoints, None, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "\n",
    "    return result\n",
    "\n",
    "def orb_bf_matcher(descriptors1, descriptors2, average=False):\n",
    "    # Create a brute-force matcher object\n",
    "    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "\n",
    "    # Perform the matching between the two descriptor sets\n",
    "    matches = bf.match(descriptors1, descriptors2)\n",
    "\n",
    "    # Sort the matches based on distance\n",
    "    matches = sorted(matches, key=lambda x: x.distance)\n",
    "\n",
    "    distance = 0.0\n",
    "    if average is True:\n",
    "        distance = sum(m.distance for m in matches) / len(matches)\n",
    "    else:\n",
    "        distance = np.median([m.distance for m in matches])\n",
    "\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Fingerprint Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_paths = list(Path(SAMPLE_DIR).rglob(\"*.png\"))\n",
    "images = []\n",
    "images_titles = []\n",
    "\n",
    "for p in images_paths:\n",
    "    img = cv2.imread(str(p), cv2.IMREAD_GRAYSCALE)\n",
    "    images.append(img)\n",
    "    images_titles.append(p.stem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Fingerprint into Probe (NO) and Gallery (WI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probe_images = []\n",
    "probe_images_titles = []\n",
    "gallery_images = []\n",
    "gallery_images_titles = []\n",
    "\n",
    "# Split the images into probe and gallery\n",
    "for image, title in zip(images, images_titles):\n",
    "    subject_id, illumination, finger_id, background, instance_id = title.split(\"_\")\n",
    "\n",
    "    if illumination == \"o\" and background == \"n\":\n",
    "        probe_images.append(image)\n",
    "        probe_images_titles.append(title)\n",
    "    else:\n",
    "        gallery_images.append(image)\n",
    "        gallery_images_titles.append(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images(probe_images, probe_images_titles, fig_size=15, sup_title=\"Probe (NO) Fingerprint Images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images(gallery_images, gallery_images_titles, fig_size=15, sup_title=\"Gallery (WI) Fingerprint Images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. ORB (Oriented FAST and Rotated BRIEF)\n",
    "\n",
    "REF: https://docs.opencv.org/4.x/dc/dc3/tutorial_py_matcher.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the ORB detector\n",
    "orb = cv2.ORB_create()\n",
    "\n",
    "# Find the keypoints and descriptors for the probe images\n",
    "probe_orb_keypoints, probe_orb_descriptors = zip(*[orb.detectAndCompute(image, None) for image in probe_images])\n",
    "\n",
    "# Find the keypoints and descriptors for the gallery images\n",
    "gallery_orb_keypoints, gallery_orb_descriptors = zip(*[orb.detectAndCompute(image, None) for image in gallery_images])\n",
    "\n",
    "# Show keypoints for each probe image\n",
    "probe_orb_keypoints_images = [imkpts(image, keypoints) for image, keypoints in zip(probe_images, probe_orb_keypoints)]\n",
    "show_images(probe_orb_keypoints_images, probe_images_titles, fig_size=15, sup_title=\"Probe (NO) ORB Keypoints\")\n",
    "\n",
    "# Show keypoints for each gallery image\n",
    "gallery_orb_keypoints_images = [imkpts(image, keypoints) for image, keypoints in zip(gallery_images, gallery_orb_keypoints)]\n",
    "show_images(gallery_orb_keypoints_images, gallery_images_titles, fig_size=15, sup_title=\"Gallery (WI) ORB Keypoints\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def orb_flann_matcher(descriptors1, descriptors2):\n",
    "    FLANN_INDEX_LSH = 6\n",
    "    index_params = dict(algorithm=FLANN_INDEX_LSH, table_number=6, key_size=12, multi_probe_level=1)\n",
    "    search_params = dict(checks=50)\n",
    "\n",
    "    # Create a FLANN matcher object\n",
    "    flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "    matches = flann.knnMatch(descriptors1, descriptors2, k=2)\n",
    "\n",
    "    # Apply ratio test\n",
    "    good_matches = []\n",
    "    for m, n in matches:\n",
    "        if m.distance < 0.75 * n.distance:\n",
    "            good_matches.append(m)\n",
    "\n",
    "    distance = np.median([m.distance for m in good_matches])\n",
    "\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distances = {k : [] for k in probe_images_titles}\n",
    "\n",
    "# for probe_desc, probe_title in zip(probe_orb_descriptors, probe_images_titles):\n",
    "#     for gallery_desc, gallery_title in zip(gallery_orb_descriptors, gallery_images_titles):\n",
    "#         values = {}\n",
    "#         values[\"gallery\"] = gallery_title\n",
    "#         values[\"distances\"] = orb_flann_matcher(probe_desc, gallery_desc)\n",
    "#         print(f\"Matching {probe_title} with {gallery_title}: Distance = {values['distances']:.2f}\")\n",
    "#         distances[probe_title].append(values)\n",
    "\n",
    "# print(distances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. BRIEF (Binary Robust Independent Elementary Features) + STAR(CenSurE)\n",
    "\n",
    "REF: https://docs.opencv.org/4.x/dc/d7d/tutorial_py_brief.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate FAST detector\n",
    "star = cv2.xfeatures2d.StarDetector_create()\n",
    "\n",
    "# Initiate BRIEF extractor\n",
    "brief = cv2.xfeatures2d.BriefDescriptorExtractor_create()\n",
    "\n",
    "# Find the keypoints and descriptors for the probe images\n",
    "probe_star_keypoints = [star.detect(image, None) for image in probe_images]\n",
    "probe_brief_keypoints, probe_brief_descriptors = zip(*[brief.compute(image, kp) for image, kp in zip(probe_images, probe_star_keypoints)])\n",
    "\n",
    "# Find the keypoints and descriptors for the probe images\n",
    "gallery_star_keypoints = [star.detect(image, None) for image in gallery_images]\n",
    "gallery_brief_keypoints, gallery_brief_descriptors = zip(*[brief.compute(image, kp) for image, kp in zip(gallery_images, gallery_star_keypoints)])\n",
    "\n",
    "# Show keypoints for each probe image\n",
    "probe_brief_keypoints_images = [imkpts(image, keypoints) for image, keypoints in zip(probe_images, probe_brief_keypoints)]\n",
    "show_images(probe_brief_keypoints_images, probe_images_titles, fig_size=15, sup_title=\"Probe (NO) BRIEF Keypoints\")\n",
    "\n",
    "# Show keypoints for each gallery image\n",
    "gallery_brief_keypoints_images = [imkpts(image, keypoints) for image, keypoints in zip(gallery_images, gallery_brief_keypoints)]\n",
    "show_images(gallery_brief_keypoints_images, gallery_images_titles, fig_size=15, sup_title=\"Gallery (WI) BRIEF Keypoints\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. SuperGlue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from superpoint_superglue_deployment import Matcher\n",
    "\n",
    "def superglue_matcher(probe_image, gallery_image):\n",
    "    superglue = Matcher()\n",
    "\n",
    "    probe_kpts, gallery_kpts, _, _, matches = superglue.match(probe_image, gallery_image)\n",
    "    _, mask = cv2.findHomography(\n",
    "        np.float64([probe_kpts[m.queryIdx].pt for m in matches]).reshape(-1, 1, 2),\n",
    "        np.float64([gallery_kpts[m.trainIdx].pt for m in matches]).reshape(-1, 1, 2),\n",
    "        method=cv2.USAC_MAGSAC,\n",
    "        ransacReprojThreshold=5.0,\n",
    "        maxIters=10000,\n",
    "        confidence=0.95,\n",
    "    )\n",
    "\n",
    "    matches = np.array(matches)[np.all(mask > 0, axis=1)]\n",
    "    matches = sorted(matches, key=lambda match: match.distance)\n",
    "    distance = np.median([m.distance for m in matches])\n",
    "    matched_image = cv2.drawMatches(\n",
    "        probe_image,\n",
    "        probe_kpts,\n",
    "        gallery_image,\n",
    "        gallery_kpts,\n",
    "        matches[:12],\n",
    "        None,\n",
    "        flags=2,\n",
    "    )\n",
    "\n",
    "    return distance, matched_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "distances = {k : [] for k in probe_images_titles}\n",
    "\n",
    "for probe_image, probe_title in zip(probe_images, probe_images_titles):\n",
    "    for gallery_image, gallery_title in zip(gallery_images, gallery_images_titles):\n",
    "        values = {}\n",
    "        values[\"gallery\"] = gallery_title\n",
    "        values[\"distances\"], _ = superglue_matcher(probe_image, gallery_image)\n",
    "        print(f\"Matching {probe_title} with {gallery_title}: Distance = {values['distances']:.2f}\")\n",
    "        distances[probe_title].append(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_probe_subjects = len(distances)\n",
    "\n",
    "thresholds = np.arange(0.30,0.80,0.01)\n",
    "DI_1_list = []\n",
    "FA_list = []\n",
    "GR_list = []\n",
    "    \n",
    "for t in thresholds:\n",
    "    DI_1 = 0\n",
    "    FA = 0\n",
    "    GR = 0\n",
    "    for probe in distances:\n",
    "        probe_subject = probe.split(\"_\")[0]\n",
    "        gallery = distances[probe]\n",
    "        all_dist = []\n",
    "        excluding_probe_dist = []\n",
    "        for g in gallery:\n",
    "            all_dist.append((g['gallery'],g['distances']))\n",
    "            if g['gallery'].split(\"_\")[0] != probe_subject:\n",
    "                excluding_probe_dist.append((g['gallery'],g['distances']))\n",
    "        all_dist = sorted(all_dist, key = lambda x : x[1])\n",
    "        excluding_probe_dist = sorted(excluding_probe_dist, key = lambda x : x[1])\n",
    "        if all_dist[0][0].split(\"_\")[0] == probe_subject and all_dist[0][1] < t:\n",
    "            DI_1 += 1\n",
    "        if excluding_probe_dist[0][1] < t:\n",
    "            FA += 1\n",
    "        else:\n",
    "            GR += 1\n",
    "\n",
    "    DI_1_list.append(DI_1)\n",
    "    FA_list.append(FA)\n",
    "    GR_list.append(GR)\n",
    "    \n",
    "DIR_1_list = np.array(DI_1_list) / num_probe_subjects\n",
    "FAR_list = np.array(FA_list) / num_probe_subjects\n",
    "GRR_list = np.array(GR_list) / num_probe_subjects\n",
    "FRR_list = 1 - DIR_1_list\n",
    "AUC = round(np.trapz(DIR_1_list,FAR_list),4)\n",
    "\n",
    "# plt.plot(thresholds, FRR_list, label=\"FRR\")\n",
    "# plt.plot(thresholds, FAR_list, label=\"FAR\")\n",
    "# plt.plot([0,1],color=\"red\",label=\"AUC = 0.5\")\n",
    "# plt.plot([0,0], [0,1],color=\"green\",label=\"AUC = 1.0\")\n",
    "# plt.plot([0,1], [1,1],color=\"green\")\n",
    "# plt.plot(FAR_list, DIR_1_list, color=\"blue\", label=\"AUC = \" + str(AUC))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# def bf_compute_distance(probe_descriptors, gallery_descriptors):\n",
    "#     bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=False)  # Adjusted crossCheck\n",
    "#     matches = bf.knnMatch(probe_descriptors, gallery_descriptors, k=2)\n",
    "\n",
    "#     # Lowe's ratio test\n",
    "#     ratio_test = 0.7\n",
    "#     good_matches = []\n",
    "\n",
    "#     for m, n in matches:\n",
    "#         if m.distance < ratio_test * n.distance:\n",
    "#             good_matches.append(m.distance)\n",
    "\n",
    "#     if good_matches:\n",
    "#           # Use median for robustness\n",
    "#         score = np.median(good_matches)\n",
    "#     else:\n",
    "#         score = np.inf  # Indicate no good matches\n",
    "\n",
    "#     return score\n",
    "\n",
    "# for probe_ds, gallery_ds in zip(probe_orb_descriptors, gallery_orb_descriptors):\n",
    "#     print(bf_compute_distance(probe_ds, gallery_ds))\n",
    "\n",
    "# for probe_ds, gallery_ds in zip(probe_brief_descriptors, gallery_brief_descriptors):\n",
    "#     print(bf_compute_distance(probe_ds, gallery_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def flann_compute_distance(probe_descriptors, gallery_descriptors):\n",
    "#     index_params = dict(algorithm=1, trees=5)\n",
    "#     search_params = dict(checks=50)\n",
    "#     flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "#     matches = flann.knnMatch(probe_descriptors, gallery_descriptors, k=2)\n",
    "\n",
    "#     # Lowe's ratio test\n",
    "#     ratio_test = 0.75\n",
    "#     good_matches = []\n",
    "\n",
    "#     for m, n in matches:\n",
    "#         if m.distance < ratio_test * n.distance:\n",
    "#             good_matches.append(m.distance)\n",
    "\n",
    "#     if good_matches:\n",
    "#         score = np.median(good_matches)  # Use median for robustness\n",
    "#     else:\n",
    "#         score = np.inf  # Indicate no good matches\n",
    "\n",
    "#     return score\n",
    "\n",
    "# for probe_ds, gallery_ds in zip(probe_orb_descriptors, gallery_orb_descriptors):\n",
    "#     print(flann_compute_distance(probe_ds, gallery_ds))\n",
    "\n",
    "# for probe_ds, gallery_ds in zip(probe_brief_descriptors, gallery_brief_descriptors):\n",
    "#     print(flann_compute_distance(probe_ds, gallery_ds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jolene3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
