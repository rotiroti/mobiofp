{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MoBioFP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import math\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "from joblib import Memory\n",
    "\n",
    "memory = Memory(location=\"cache/detection\", verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define global constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_DIR = \"../data/raw/samples\"\n",
    "MODEL_CHECKPOINT = \"YOLO_MODEL_CHECKPOINT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mobiofp.utils import find_largest_connected_component, to_fingerprint, enhance_fingerprint\n",
    "\n",
    "def show_images(images, titles, cmap=\"gray\", show_axis=False, fig_size=10, sup_title=None):\n",
    "    assert((titles is None) or (len(images) == len(titles)))\n",
    "\n",
    "    num_images = len(images)\n",
    "    num_cols = 4\n",
    "    num_rows = math.ceil(num_images / num_cols)\n",
    "\n",
    "    fig_height = fig_size * (num_rows / num_cols) * 1.5\n",
    "    _, axes = plt.subplots(num_rows, num_cols, figsize=(fig_size, fig_height), constrained_layout=True)\n",
    "    axes = axes.ravel()\n",
    "\n",
    "    if sup_title:\n",
    "        plt.suptitle(sup_title, fontsize=24)\n",
    "\n",
    "    for idx, (image, title) in enumerate(zip(images, titles)):\n",
    "        axes[idx].imshow(image, cmap=cmap)\n",
    "        axes[idx].set_title(title, fontsize=12)\n",
    "        axes[idx].axis(\"on\" if show_axis else \"off\")\n",
    "    \n",
    "    # Hide the remaining subplots\n",
    "    for idx in range(num_images, num_cols * num_rows):\n",
    "        axes[idx].axis(\"off\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "def show_iqa(sharpness_scores, contrast_scores, mask_coverage_scores):\n",
    "    _, axes = plt.subplots(1, 3, figsize=(20, 5), constrained_layout=True)\n",
    "    plt.suptitle(\"Fingertip Image-Quality Assesment\", fontsize=16)\n",
    "\n",
    "    sns.boxplot(sharpness_scores, ax=axes[0], color=\"blue\")\n",
    "    axes[0].set_xlabel(\"Sharpness Score\")\n",
    "    axes[0].set_ylabel(\"Density\")\n",
    "\n",
    "    sns.boxplot(contrast_scores, ax=axes[1], color=\"red\")\n",
    "    axes[1].set_xlabel(\"Contrast Score\")\n",
    "    axes[1].set_ylabel(\"Density\")\n",
    "\n",
    "    sns.boxplot(mask_coverage_scores, ax=axes[2], color=\"green\")\n",
    "    axes[2].set_xlabel(\"Binary Mask Coverage Score\")\n",
    "    axes[2].set_ylabel(\"Density\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def post_process_mask(mask):\n",
    "    # Apply morphological operation and Gaussian blur\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel, iterations=2)\n",
    "    mask = cv2.GaussianBlur(mask, (5, 5), sigmaX=2, sigmaY=2, borderType=cv2.BORDER_DEFAULT)\n",
    "    mask = np.where(mask < 127, 0, 255).astype(np.uint8)\n",
    "\n",
    "    # Find the largest connected component\n",
    "    mask = find_largest_connected_component(mask)\n",
    "\n",
    "    return mask\n",
    "\n",
    "def fingertip_enhancement(image):\n",
    "    # Convert to grayscale\n",
    "    if len(image.shape) > 2:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Normalize, bilateral filter, and CLAHE\n",
    "    image = cv2.normalize(image, None, 0, 255, cv2.NORM_MINMAX)\n",
    "    image = cv2.bilateralFilter(image, 7, 50, 50)\n",
    "    image = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8)).apply(image)\n",
    "\n",
    "    return image\n",
    "\n",
    "@memory.cache\n",
    "def from_fingertip_to_fingerprint(image):\n",
    "    # Fingertip Adaptive Thresholding\n",
    "    binary = cv2.adaptiveThreshold(image, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 21, 2)\n",
    "\n",
    "    try:\n",
    "        fingerprint = to_fingerprint(binary)\n",
    "\n",
    "        return fingerprint\n",
    "    except Exception as e:\n",
    "        print(f\"Error converting fingerphoto to fingerprint: {e}\")\n",
    "        return None\n",
    "\n",
    "@memory.cache\n",
    "def fingerprint_enhancement(image):\n",
    "    fingerprint = enhance_fingerprint(image)\n",
    "    fingerprint = fingerprint.astype(\"uint8\")\n",
    "\n",
    "    return fingerprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read sample images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imutils import rotate_bound\n",
    "\n",
    "images_paths = list(Path(SAMPLE_DIR).rglob(\"*.jpg\"))\n",
    "images = []\n",
    "images_titles = []\n",
    "\n",
    "# Read sample images\n",
    "for p in images_paths:\n",
    "    img = cv2.imread(str(p))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = rotate_bound(img, 90)\n",
    "    images.append(img)\n",
    "    images_titles.append(p.stem)\n",
    "\n",
    "show_images(images, images_titles, fig_size=15, sup_title=\"Sample Fingerphoto Images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fingertip detection using YOLOv8n pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(MODEL_CHECKPOINT)\n",
    "model.info()\n",
    "results = model(images, stream=True, conf=0.80, max_det=1)\n",
    "\n",
    "predicted_images = []\n",
    "bbox_coords = []\n",
    "fingertip_images = []\n",
    "\n",
    "for result in results:\n",
    "    boxes = result.boxes.xyxy.tolist()\n",
    "    boxes = [int(coord) for coord in boxes[0]]\n",
    "    bbox_coords.append(boxes)    \n",
    "    \n",
    "    original = result.orig_img\n",
    "    x1, y1, x2, y2 = boxes\n",
    "    fingertip = original[y1:y2, x1:x2]\n",
    "    fingertip_images.append(fingertip)\n",
    "\n",
    "    predicted = result.plot()\n",
    "    predicted_images.append(predicted)\n",
    "\n",
    "show_images(predicted_images, images_titles, fig_size=15, sup_title=\"YOLOv8n Fingertip Detection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images(fingertip_images, images_titles, sup_title=\"Fingertip Images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rembg import remove, new_session\n",
    "\n",
    "# Initialize the rembg session\n",
    "rembg_session = new_session(\"isnet-general-use\")\n",
    "\n",
    "# Remove background from the cropped images\n",
    "fingertip_masks = [remove(fingertip, only_mask=True, session=rembg_session) for fingertip in fingertip_images]\n",
    "\n",
    "# Post-process masks\n",
    "fingertip_masks = [post_process_mask(mask) for mask in fingertip_masks]\n",
    "\n",
    "show_images(fingertip_masks, images_titles, sup_title=\"Fingertip Masks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fingertip Image-Quality Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mobiofp.utils import quality_scores\n",
    "\n",
    "sharpness_scores = []\n",
    "contrast_scores = []\n",
    "mask_coverage_scores = []\n",
    "\n",
    "for image, mask in zip(fingertip_images, fingertip_masks):\n",
    "    sharpness_score, contrast_score, mask_coverage_scorere = quality_scores(image, mask)\n",
    "    sharpness_scores.append(sharpness_score)\n",
    "    contrast_scores.append(contrast_score)\n",
    "    mask_coverage_scores.append(mask_coverage_scorere)\n",
    "\n",
    "show_iqa(sharpness_scores, contrast_scores, mask_coverage_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of images before filtering: {len(fingertip_images)}\")\n",
    "print(f\"Number of masks before filtering: {len(fingertip_masks)}\")\n",
    "\n",
    "# NOTE:\n",
    "#\n",
    "# For the scope of this demonstration, we will consider only the binary mask coverage score\n",
    "# and we will not consider the sharpness and contrast scores. The binary mask coverage threshold\n",
    "# is set to 70% only to include all the images in the dataset since the dataset is already too small\n",
    "# and we want to demonstrate the next steps of the pipeline.\n",
    "BINARY_MASK_COVERAGE_THRESH = 70.0\n",
    "\n",
    "iqa_images = []\n",
    "iqa_masks = []\n",
    "iqa_titles = []\n",
    "\n",
    "for mcs, fingertip, fingertip_mask, fingertip_title in zip(mask_coverage_scores, fingertip_images, fingertip_masks, images_titles):\n",
    "    if mcs >= BINARY_MASK_COVERAGE_THRESH:\n",
    "        iqa_images.append(fingertip)\n",
    "        iqa_masks.append(fingertip_mask)\n",
    "        iqa_titles.append(fingertip_title)\n",
    "\n",
    "assert len(iqa_images) == len(iqa_masks) == len(iqa_titles)\n",
    "\n",
    "print(f\"Number of images after filtering: {len(iqa_images)}\")\n",
    "print(f\"Number of masks after filtering: {len(iqa_masks)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fingertip Enhancement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grayscale_images = [cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) for image in iqa_images]\n",
    "grayscale_images = [cv2.bitwise_and(image, image, mask=mask) for image, mask in zip(grayscale_images, iqa_masks)]\n",
    "\n",
    "show_images(grayscale_images, iqa_titles, cmap=\"gray\", sup_title=\"Grayscale Fingertip Images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fingertip_enhanced_images = [fingertip_enhancement(image) for image in grayscale_images]\n",
    "\n",
    "show_images(fingertip_enhanced_images, iqa_titles, sup_title=\"Fingertip Enhanced Images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contactless (fingertip fingerphoto) to Contact (fingerprint) Image Conversion\n",
    "\n",
    "The function `to_fingerprint()` takes an fingertip-enhanced and converts it into a fingerprint image.\n",
    "It does this by:\n",
    "\n",
    "- Resizing the image.\n",
    "- Calculating the local gradient of the image using Sobel filters.\n",
    "- Calculating the orientation of the ridges in the fingerprint.\n",
    "- Extracting a region of the image and smoothing it to reduce noise.\n",
    "- Calculating the x-signature of the region and finding its local maxima to estimate the ridge period.\n",
    "- Creating a bank of Gabor filters with different orientations.\n",
    "- Filtering the image with each filter in the bank.\n",
    "- Assembling the final result by taking the corresponding convolution result for each pixel based on the closest orientation in the Gabor bank.\n",
    "- Converting the result to grayscale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fingerprints, fingerprint_titles = [], []\n",
    "\n",
    "for image, title in zip(fingertip_enhanced_images, iqa_titles):\n",
    "    fingerprint = from_fingertip_to_fingerprint(image)\n",
    "    if fingerprint is not None:\n",
    "        fingerprints.append(fingerprint)\n",
    "        fingerprint_titles.append(title)\n",
    "\n",
    "show_images(fingerprints, fingerprint_titles, sup_title=\"Fingerprint Images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply fingerprint enhancement using Fingerprint-Enhancement-Python package\n",
    "#\n",
    "# Ref: https://github.com/Utkarsh-Deshmukh/Fingerprint-Enhancement-Python\n",
    "#\n",
    "# NOTE: This step is one of the slowest steps in the end-to-end pipeline for our fingerphoto matching algorithm\n",
    "fingerprint_enhanced_images = [fingerprint_enhancement(fingerprint) for fingerprint in fingerprints]\n",
    "\n",
    "show_images(fingerprint_enhanced_images, iqa_titles, sup_title=\"Fingerprint Enhanced Images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Contact (fingerprint) Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROCESSED_DIR = Path(\"../data/processed/samples/detection\")\n",
    "PROCESSED_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for image, title in zip(fingerprint_enhanced_images, fingerprint_titles):\n",
    "    fingerprint_path = PROCESSED_DIR / f\"{title}.png\"\n",
    "    cv2.imwrite(str(fingerprint_path), image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jolene3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
